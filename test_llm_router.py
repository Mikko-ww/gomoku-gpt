#!/usr/bin/env python3
"""
LLMè·¯ç”±å™¨æµ‹è¯•è„šæœ¬
æµ‹è¯•å„ç§æä¾›å•†çš„æ¥å£æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import asyncio
from llm_router import LLMRouter, LLMMessage
from logger import logger

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    logger.info("å¼€å§‹æµ‹è¯•LLMè·¯ç”±å™¨åŸºæœ¬åŠŸèƒ½...")
    
    # å°è¯•å¯¼å…¥é…ç½®
    try:
        from config import API_KEYS, DEFAULT_PROVIDER
        config = {
            "default_provider": DEFAULT_PROVIDER,
            "providers": API_KEYS
        }
        router = LLMRouter(config)
        logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶åˆå§‹åŒ–ï¼Œé»˜è®¤æä¾›å•†: {DEFAULT_PROVIDER}")
    except ImportError:
        logger.info("ä½¿ç”¨ç¯å¢ƒå˜é‡åˆå§‹åŒ–")
        router = LLMRouter()
    
    # æ˜¾ç¤ºå¯ç”¨æä¾›å•†
    available = router.get_available_providers()
    logger.info(f"å¯ç”¨æä¾›å•†: {available}")
    
    if not available:
        logger.error("æ²¡æœ‰å¯ç”¨çš„æä¾›å•†ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    # æµ‹è¯•ç®€å•å¯¹è¯
    test_system = "ä½ æ˜¯ä¸€ä¸ªäº”å­æ£‹åŠ©æ‰‹ã€‚è¯·ç®€çŸ­å›ç­”ã€‚"
    test_user = "äº”å­æ£‹çš„åŸºæœ¬è§„åˆ™æ˜¯ä»€ä¹ˆï¼Ÿè¯·ç”¨ä¸€å¥è¯å›ç­”ã€‚"
    
    for provider in available:
        logger.info(f"\n--- æµ‹è¯• {provider} æä¾›å•† ---")
        try:
            response = router.simple_chat(
                system=test_system,
                user=test_user,
                provider=provider,
                max_tokens=100
            )
            logger.success(f"{provider} æµ‹è¯•æˆåŠŸ:")
            logger.info(f"å›å¤: {response}")
        except Exception as e:
            logger.error(f"{provider} æµ‹è¯•å¤±è´¥: {e}")

def test_multiple_providers():
    """æµ‹è¯•å¤šæä¾›å•†åˆ‡æ¢"""
    logger.info("\nå¼€å§‹æµ‹è¯•å¤šæä¾›å•†åˆ‡æ¢...")
    
    try:
        from config import API_KEYS, DEFAULT_PROVIDER
        config = {
            "default_provider": DEFAULT_PROVIDER,
            "providers": API_KEYS
        }
        router = LLMRouter(config)
    except ImportError:
        router = LLMRouter()
    
    available = router.get_available_providers()
    
    if len(available) < 2:
        logger.warning("åªæœ‰ä¸€ä¸ªæä¾›å•†å¯ç”¨ï¼Œè·³è¿‡åˆ‡æ¢æµ‹è¯•")
        return
    
    # æµ‹è¯•åˆ‡æ¢é»˜è®¤æä¾›å•†
    for provider in available[:2]:  # æµ‹è¯•å‰ä¸¤ä¸ª
        logger.info(f"\nè®¾ç½®é»˜è®¤æä¾›å•†ä¸º: {provider}")
        router.set_default_provider(provider)
        
        try:
            response = router.simple_chat(
                system="ä½ æ˜¯åŠ©æ‰‹",
                user="è¯·å›ç­”ï¼š1+1ç­‰äºå‡ ï¼Ÿ",
                max_tokens=50
            )
            logger.success(f"ä½¿ç”¨ {provider} æˆåŠŸ: {response.strip()}")
        except Exception as e:
            logger.error(f"ä½¿ç”¨ {provider} å¤±è´¥: {e}")

def test_message_format():
    """æµ‹è¯•æ¶ˆæ¯æ ¼å¼"""
    logger.info("\nå¼€å§‹æµ‹è¯•æ¶ˆæ¯æ ¼å¼...")
    
    try:
        from config import API_KEYS, DEFAULT_PROVIDER
        config = {
            "default_provider": DEFAULT_PROVIDER,
            "providers": API_KEYS
        }
        router = LLMRouter(config)
    except ImportError:
        router = LLMRouter()
    
    available = router.get_available_providers()
    if not available:
        logger.error("æ²¡æœ‰å¯ç”¨çš„æä¾›å•†")
        return
    
    # æµ‹è¯•æ¶ˆæ¯åˆ—è¡¨æ ¼å¼
    messages = [
        LLMMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹"),
        LLMMessage(role="user", content="2+2ç­‰äºå‡ ï¼Ÿ"),
        LLMMessage(role="assistant", content="2+2ç­‰äº4"),
        LLMMessage(role="user", content="é‚£3+3å‘¢ï¼Ÿ")
    ]
    
    try:
        response = router.chat_completion(
            messages=messages,
            max_tokens=50
        )
        logger.success(f"æ¶ˆæ¯æ ¼å¼æµ‹è¯•æˆåŠŸ: {response.content}")
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {response.model}")
        logger.info(f"Tokenä½¿ç”¨: {response.usage}")
    except Exception as e:
        logger.error(f"æ¶ˆæ¯æ ¼å¼æµ‹è¯•å¤±è´¥: {e}")

def test_model_switching():
    """æµ‹è¯•æ¨¡å‹åˆ‡æ¢"""
    logger.info("\nå¼€å§‹æµ‹è¯•æ¨¡å‹åˆ‡æ¢...")
    
    try:
        from config import API_KEYS, DEFAULT_PROVIDER, RECOMMENDED_MODELS
        config = {
            "default_provider": DEFAULT_PROVIDER,
            "providers": API_KEYS
        }
        router = LLMRouter(config)
    except ImportError:
        router = LLMRouter()
        RECOMMENDED_MODELS = {
            "openrouter": ["openai/gpt-3.5-turbo", "openai/gpt-oss-20b:free"]
        }
    
    available = router.get_available_providers()
    if not available:
        return
    
    # æµ‹è¯•æŒ‡å®šæ¨¡å‹
    provider = available[0]
    models_to_test = RECOMMENDED_MODELS.get(provider, [])[:2]  # æµ‹è¯•å‰ä¸¤ä¸ªæ¨¡å‹
    
    for model in models_to_test:
        logger.info(f"æµ‹è¯• {provider} çš„æ¨¡å‹ {model}")
        try:
            response = router.simple_chat(
                system="ä½ æ˜¯åŠ©æ‰‹",
                user="è¯´hello",
                provider=provider,
                model=model,
                max_tokens=30
            )
            logger.success(f"æ¨¡å‹ {model} æµ‹è¯•æˆåŠŸ: {response}")
        except Exception as e:
            logger.error(f"æ¨¡å‹ {model} æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸš€ LLMè·¯ç”±å™¨æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    try:
        # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
        test_basic_functionality()
        
        # å¤šæä¾›å•†æµ‹è¯•
        test_multiple_providers()
        
        # æ¶ˆæ¯æ ¼å¼æµ‹è¯•
        test_message_format()
        
        # æ¨¡å‹åˆ‡æ¢æµ‹è¯•
        test_model_switching()
        
        print("\n" + "=" * 50)
        print("âœ… æµ‹è¯•å®Œæˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("\nâŒ æµ‹è¯•å¤±è´¥")